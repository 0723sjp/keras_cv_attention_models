# Attention layers
***

## Summary
  - Defined layers / functions from model structures.
  - `MHSAWithPositionEmbedding` from `botnet`.
  - `outlook_attention` and `outlook_attention_simple` from `volo`.
  - `rsoftmax` and `split_attention_conv2d` from `resnest`
  - `HaloAttention` from `halonet`
***
